#!/bin/bash

# Copyright (C) 2007-2017 University of Oxford
# Authors: Dave Flitney, Stephen Smith, Matthew Webster and Duncan Mortimer

# SHCOPYRIGHT

###########################################################################
# Edit this file in order to setup FSL to use your local compute
# cluster.
###########################################################################

# Exit states
INVALID_SYNTAX="64"
NO_CUDA="65"
NO_CUDA_TYPE="66"
MISS_CONFIGURED="67"
ARG_MISSING_VALUE="68"
MISSING_FILE="69"
NO_CUDA_VERSION="70"
NO_EXECUTABLE="71"
BAD_QUEUE="72"

# Functions
# Validate passed arguments - takes number of arguments and the argument string
with_arguments () {
    nargs=$1
    REGEX="-.*"
    for (( arg=0; arg<"$nargs"; arg++ )); do
        if [[ "$2" =~ $REGEX ]]; then
            usage "$ARG_MISSING_VALUE"
        fi
        shift
    done
}

# Augment the complexes with the passed complex name and value
add_complex () {
    complexes="$complexes -l $1=\"$2\""
}

# Join the second argument array with the first argument delimeter
join_list ()
{
    delimeter=$1
    array=("${@:2}")
    array_string=$(printf "$delimeter%s" "${array[@]}")
    echo "${array_string:1}"
}

index_in_list ()
{
    local index=0
    local match="$1"
    local values="${@:2}"
    for value in $values; do
        if [ "$value" = "$1" ]; then
            echo "$index"
            return
        fi
        ((index++))
    done
    echo "$index"
}

###########################################################################
# The following section determines what to do when fsl_sub is called
# by an FSL program. If SGE_ROOT is set it will attempt to pass the
# commands onto the cluster, otherwise it will run the commands
# itself. There are two values for the METHOD variable, "SGE" and
# "NONE". Note that a user can unset SGE_ROOT if they don't want the
# cluster to be used.
###########################################################################
METHOD=SGE

POSIXLY_CORRECT=${OLD_POSIXLY_CORRECT}
export POSIXLY_CORRECT

###########################################################################
# If you have a Parallel Environment configured for OpenMP tasks then
# the variable omp_pe should be set to the name you have defined for that
# PE. The script will work out which queues have that PE setup on them.
# Note, we support openmp tasks even when Grid Engine is not in use.
###########################################################################

omp_pe='shmem'


###########################################################################
# If you wish to disable processor affinities under Grid Engine then
# comment the following line.
# This instructs Grid Engine to bind the task to the number of job slots
# allocated to the job (or PE)
###########################################################################
proc_affinities="-binding linear:slots"


###########################################################################
# The following sets up the default queue name, which you may want to
# change. It also sets up the basic emailing control.
###########################################################################

default_queue=long.qc
mailto=$(whoami)@$(hostname -f | cut -d . -f 2-)
MailOpts="a"


###########################################################################
# The following sets up the CUDA queue, which you will need to change to
# match your environment.
###########################################################################

# Change this to 0 if you do not have CUDA hardware.
cuda_available=1
# Name the CUDA queue here.
cuda_queue="gpu.q"
# Define the Univa GPU complex here
cuda_gpu_resource="gpu"
# Do we care about GPU hardware classes?
cuda_classes_available=1
# GPU Hardware class configuration
cuda_class_resource="gputype"
# Define the CUDA hardware classes available here (e.g. what -y options
# are acceptable on your system) and the default type. The classes can only
# be single characters
cuda_types=("G" "K" "P" "V")
# And the resource strings that correspond to these
cuda_type_names=("TitanX" "k80"  "v100" "p100")
# Provide some helpful info to your user about the available classes
cuda_type_docs="Available CUDA hardware classes are
  G - TitanX. No-ECC, single-precision workloads
  K - Kepler. ECC, double- or single-precision workloads
  P - Pascal. ECC, double-, single- and half-precision workloads
  V - Volta. ECC, double-, single-, half- and quarter-precision workloads"
# Default CUDA type
cuda_type_default="K"

# If your system is configured to use Shell Modules for environment setup
# and you have appropriate versioned CUDA modules define this variable as '1'
cuda_uses_modules=1
# The next setting defines the parent to your versioned CUDA modules, e.g.
# 'cuda' would mean you would load CUDA 9 with 'module load cuda/9'
cuda_modules="cuda"

# This works out which modules you have available
if [ $cuda_uses_modules ]; then
    # Define the Shell Module prefix for the CUDA Libraries - module name
    # should match the toolkit version
    cuda_modules_available=$(module avail $cuda_modules 2>&1 | \
        sed -e 's/---.*---//' | tr -s ' ' | tr -d '\n' | \
        awk 'NF>1{print $NF}' | sed "s/$cuda_modules\///")
    cuda_modules_default=$(echo "$cuda_modules_available" | awk 'NF>1{print $NF}')     
fi
# If you don't use Shell Modules make sure the libraries are available

#unset module
if [ "x$SGE_ROOT" = "x" ] ; then
	METHOD=NONE
else
	QCONF=$(which qconf)
	if [ "x$QCONF" = "x" ]; then
		METHOD=NONE
		echo "Warning: SGE_ROOT environment variable is set but Grid Engine software not found, will run locally" >&2
	fi
fi

# stop submitted scripts from submitting jobs themselves
if [ "X$FSLSUBALREADYRUN" = "Xtrue" ] ; then
    METHOD=NONE
    echo "Warning: job on queue attempted to submit parallel jobs - running jobs serially instead" >&2
fi

if [ "X$METHOD" = "XNONE" ]; then
	QCONF=echo
fi
FSLSUBALREADYRUN=true
export FSLSUBALREADYRUN

###########################################################################
# The following auto-decides what cluster queue to use. The calling
# FSL program will probably use the -T option when calling fsl_sub,
# which tells fsl_sub how long (in minutes) the process is expected to
# take (in the case of the -t option, how long each line in the
# supplied file is expected to take). You need to setup the following
# function to map ranges of timings into your cluster queues - it doesn't
# matter how many you setup, that's up to you.
###########################################################################

map_qname ()
{
    duration=$1
    qtype='c'

    
    if [ "$duration" -le 1440 ]; then
        qduration='short'
    elif [ "$duration" -le 10080 ] ; then
        qduration='long'
    else
        return 1
    fi

    queue="${qduration}.q${qtype}"
    #echo "Estimated time was $1 mins: queue name is $queue"
}

###########################################################################
# The following auto-decides what CUDA queue to use. The calling
# FSL program will probably use the -T option when calling fsl_sub,
# which tells fsl_sub how long (in minutes) the process is expected to
# take (in the case of the -t option, how long each line in the
# supplied file is expected to take). You need to setup the following
# function to map ranges of timings into your cluster queues - it doesn't
# matter how many you setup, that's up to you.
###########################################################################

map_cuda_qname ()
{
    duration=$1

    # No resource specific queues...
    queue="${cuda_queue}"
    if [ "$verbose" ]; then
        echo "Estimated time was $1 mins: queue name is $queue" >&2
    fi
}

###########################################################################
# The following makes any modifications to queue parameters based on
# promised RAM requirements as specified by the -R option when calling 
# fsl_sub, which tells fsl_sub how much RAM the job is expected to require
# (in GB) (in the case of the -t option, the RAM promise applies to  each 
# line in the supplied file). You need to setup the following
# list to map ranges of timings into your cluster queues - it doesn't
# matter how many you setup, that's up to you.
###########################################################################

map_ram ()
{
    ram=$1
    max_ram="16"
    slots=$(("$ram" / "$max_ram"))
    if [ $(("$ram" % "$max_ram")) ]; then
        slots=$(("$slots" + 1))
    fi

    if [ "$slots" -gt 1 ]; then
        if [ -z "$peName" ]; then
            peName="$omp_pe"
            peThreads="$slots"
        else
            if [ "$peThreads" -lt "$slots" ]; then
                peThreads="$slots"
            fi
        fi
    fi
    if [ "$verbose" ]; then
        echo "Estimated RAM was ${ram} GB, this needs ${slots}" >&2
    fi
}

###########################################################################
# The following makes any modifications to queue parameters based on
# requested GPU class (assuming gpu classes are configured) as defined
# by the --cuda_type option to fsl_sub.
###########################################################################

map_gpu_class ()
{
    class="$1"
    REGEX="$class "
    if [[ ! "${cuda_types[@]}" =~ $REGEX ]]; then
        echo "CUDA hardware class $class not recognised" >&2
        echo "$cuda_type_docs" >&2
        exit $NO_CUDA_TYPE
    fi
    echo "TYPES TO BE PASSED ---${cuda_types[@]}---"
    lowest_hardware=$(index_in_list "$class" "${cuda_types[@]}")
    if [ "$lowest_hardware" -eq 0 ]; then
        echo "Unknown CUDA hardware class $class" >&2
        exit $MISS_CONFIGURED
    fi
    cuda_complex=$(join_list "|" "${cuda_type_names[@]:$lowest_hardware}")
    add_complex "$cuda_class_resource" "$cuda_complex"
}

###########################################################################
# Don't change the following (but keep scrolling down!)
###########################################################################

OLD_POSIXLY_CORRECT=${POSIXLY_CORRECT}
POSIXLY_CORRECT=1
export POSIXLY_CORRECT
command=$(basename "$0")

usage ()
{
  if [ -n "$1" ]; then
    rval="$1"
  else
    rval="$INVALID_SYNTAX"
  fi
  width=$(tput cols)
  fold -w "$width" >&2 <<USAGE_EOF

$command V1.1 - wrapper for job control system such as SGE

Usage: $command [options] <command>

$command gzip *.img *.hdr
$command -q short.q gzip *.img *.hdr
$command -a darwin regscript rawdata outputdir ...

  -T <minutes>          Estimated job length in minutes, used to auto-set queue name
  -q <queuename>        Possible values for <queuename> are "verylong.q", "long.q" 
                        and "short.q". See below for details
                        Default is "long.q".
  -a <arch-name>        Architecture [e.g., darwin or lx24-amd64]
  -p <job-priority>     Lower priority [0:-1024] default = 0                 
  -M <email-address>    Who to email, default = $(whoami)@$(hostname) 
  -j <jid>              Place a hold on this task until job jid has completed
  -t <filename>         Specify a task file of commands to execute in parallel
  -x <number>           Specify the maximum number of parallel job sub-tasks to run
                        concurrently.
  -N <jobname>          Specify jobname as it will appear on queue
  -R <RAM>              Max total RAM to use for job (integer in MB)
  -l <logdirname>       Where to output logfiles
  -m <mailoptions>      Change the SGE mail options, see qsub for details
  -z <output>           If <output> image or file already exists, do nothing and exit
  -F                    Use flags embedded in scripts to set SGE queuing options
  -s <pename>,<threads> Submit a multi-threaded task - requires a PE (<pename>) to be
                        configured for the requested queues.
                        <threads> specifies the number of threads to run
  -c                    Request a CUDA capable device
  -y                    Request a specific CUDA device type
                        $cuda_type_docs
  -C <version>          Request a specific CUDA version, e.g.
                        $cuda_modules_available
  -v                    Verbose mode.

Queues:

There are several batch queues configured on the cluster, each with defined CPU
time limits. All queues, except bigmem.q, have a 16GB memory limit.

short.qc:   This queue is for jobs which last under 24h.
long.qc:    This queue is for jobs which last less than 7 days

USAGE_EOF
  exit "$rval"
}

nargs=$#
if [ "$nargs" -eq 0 ] ; then
  usage
fi

#set -- "$(getopt T:q:a:p:M:j:t:z:N:R:Fvm:l:s:cy:C:x: "$@")"
#result=$?
#if [ "$result" != 0 ] ; then
#  echo "What? Your arguments make no sense!" >&2
#fi

#if [ "$nargs" -eq 0 ] || [ "$result" != 0 ] ; then
#  usage
#fi


###########################################################################
# In the following, you might want to change the behaviour of some
# flags so that they prepare the right arguments for the actual
# cluster queue submission program, in our case "qsub".
#
# -a sets is the cluster submission flag for controlling the required
# hardware architecture (normally not set by the calling program)
#
# -p set the priority of the job - ignore this if your cluster
# environment doesn't have priority control in this way.
#
# -j tells the cluster not to start this job until cluster job ID $jid
# has completed. You will need this feature.
#
# -t will pass on to the cluster software the name of a text file
# containing a set of commands to run in parallel; one command per
# line.
#
# -x will limit the number of concurrently running sub-tasks to the
# provided number of jobs
#
# -N option determines what the command will be called when you list
# running processes.
#
# -l tells the cluster what to call the standard output and standard
# -error logfiles for the submitted program.
#
# -c will request a CUDA capable resource
#   (-q can be used to override the default cuda queue)
#
# -y will request a specific CUDA hardware generation and takes the
# values:
#   G - GeForce hardware (single-precision optimised, no-ECC)
#   K - Kepler class (double-precision optimised, ECC)
#   P - Pascal class (as per K but with half-precision)
#   V - Volta class (as per P but with quarter-precision)
#
# -C will request a specific CUDA SDK version number, e.g. 6, 6.5, 7 etc
#
###########################################################################


if [ -z "$FSLSUBVERBOSE" ] ; then
    verbose=0
else
    verbose="$FSLSUBVERBOSE";
    echo "METHOD=$METHOD : args=" "$@" >&2
fi

scriptmode=0
cuda_job=0
cuda_version="$cuda_modules_default"
cuda_type="$cuda_type_default"
cuda_multi_gpu=1
complexes=''
queue=''
job_time=''
job_ram=''
sge_arch=''


while :
do
    case "$1" in
        -z|--fileisimage)
            with_arguments 1 "$@"
            if [ -e "$2" -o "$("${FSLDIR}/bin/imtest" "$2")" = 1 ] ; then
                exit 0
            fi
            shift 2
        ;;
        -T|--jobtime)
            with_arguments 1 "$@"
            job_time "$2"
            shift 2
        ;;
        -R|--jobram)
            with_arguments 1 "$@"
            job_ram "$2"
            shift 2
        ;;
        -q|--queue)
            with_arguments 1 "$@"
            queue="$2"
            queueCmd=" -q $queue "
            shift 2
        ;;
        -c|--cuda)
            if [ "$cuda_available" ]; then
                cuda_job=1
            else
                echo "CUDA devices not available" >&2
                exit "$NO_CUDA"
            fi
            shift
        ;;
        --cuda_type)
            with_arguments 1 "$@"
            cuda_type="$2"
            shift 2
        ;;
        -cuda_version)
            with_arguments 1 "$@"
            cuda_version="$2"
            if [ ! "$cuda_uses_modules" ]; then
                echo "CUDA Shell Modules not configured, ignoring requested CUDA version" >&2
            fi
            shift 2
        ;;
        --multi_gpu)
            with_arguments 1 "$@"
            cuda_multi_gpu="$2"
            shift 2
        ;;
        -a|--arch)
            with_arguments 1 "$@"
            acceptable_arch="no"
            available_archs=$(qhost | tail -n +4 | awk '{print $2}' | sort | uniq)
            for a in "${available_archs[@]}"; do
                if [ "$2" = "$a" ] ; then
                    acceptable_arch="yes"
                fi
            done
            if [ "$acceptable_arch" = "yes" ]; then
                sge_arch="-l arch=$2"
            else
                echo "Sorry arch of $2 is not supported on this GE configuration!" >&2
                echo "Should be one of: ${available_archs[*]}" >&2
                exit "$INVALID_SYNTAX"
            fi
            shift 2
        ;;
        -r|--resource)
            with_arguments 1 "$@"
            REGEX=".+=.+"
            if [[ "$2" =~ $REGEX ]]; then
                complexes="$complexes -l $2"
            else
                echo "Resource requests should take form, resource=value" >&2
                exit "$INVALID_SYNTAX"
            fi
            shift 2
        ;;
        -p|--priority)
            with_arguments 1 "$@"
            sge_priority="-p $2"
            shift 2
        ;;
        -M|--mailto)
            with_arguments 1 "$@"
            mailto="$2"
            shift 2
        ;;
        -j|--jobhold)
            with_arguments 1 "$@"
            jid="$2"
            sge_hold="-hold_jid $jid"
            shift 2
        ;;
        -t|--paralleltask)
            with_arguments 1 "$@"    
            taskfile="$2"
            if [ -f "$taskfile" ] ; then
                tasks=$(wc -l "$taskfile" | awk '{print $1}')
                if [ "$tasks" -ne 0 ]; then
                    sge_tasks="-t 1-$tasks"
                else
                    echo "Task file ${taskfile} is empty" >&2
                    echo "Should be a text file listing all the commands to run!" >&2
                    usage "$INVALID_SYNTAX"
                fi
            else
                echo "Task file (${taskfile}) does not exist" >&2
                exit "$MISSING_FILE"
            fi
            shift 2
        ;;
        -x|--parallellimit)
            with_arguments 1 "$@"
            max_parallel_jobs="$2"
            REGEX="[[:digit:]]+"
            if [[ ! "$max_parallel_jobs" =~ $REGEX ]]; then
                echo "Maximum concurrent parallel jobs should be an integer." >&2
                usage "$INVALID_SYNTAX"
            fi
            shift 2
        ;;
        -N|--name)
            with_arguments 1 "$@"
            JobName="$2";
            shift 2
        ;;
        -m|--mailoptions)
            MailOpts="$2";
            shift 2
        ;;
        -l|--logdir)
            with_arguments 1 "$@"
            LogOpts="-o $2 -e $2";
            LogDir="${2}/";
            if [ ! -e "${2}" ]; then 
                mkdir -p "$2"
            else
                REGEX="^/dev/null$"
                if [[ ! "${2}" =~ $REGEX ]] && [ -f "${2}" ]; then
                    echo "Log destination is a file (should be a folder)" >&2
                    usage "$INVALID_SYNTAX"
                fi
            fi
            shift 2
        ;;
        -F|--usescript)
            scriptmode=1
            shift
        ;;
        -v|--verbose)
            verbose=1
            shift
        ;;
        -s|--parallelenv)
            with_arguments 1 "$@"
            pe_string="$2";
            peName=$(echo "$pe_string" | cut -d',' -f 1)
            peThreads=$(echo "$pe_string" | cut -d',' -f 2)
            shift 2
        ;;
        --)
            shift
            break
        ;;
        -*)
            echo "Unrecognised option $1" >&2
            usage "$INVALID_SYNTAX"
        ;;
        *)
            break
        ;;
    esac
done

###########################################################################
# Don't change the following (but keep scrolling down!)
###########################################################################

# If job resources are specified, choose the queue automatically
if [ -z "$queue" ]; then
    if [ -n "$job_time" ]; then
        if [ "$cuda_job" ]; then
            map_cuda_qname \"$job_time\"
        else
            map_qname \"$job_time\"
        fi
    else
        if [ "$cuda_job" ]; then
            queue="$cuda_queue"
        else
            queue="$default_queue"
        fi
    fi
fi

# Queue modifications based on RAM
if [ -n "$job_ram" ]; then
    map_ram "$job_ram"
fi

$QCONF -sq "$queue" >/dev/null 2>&1
if [ $? -eq 1 ]; then
    echo "Invalid queue specified!" >&2
    exit "$BAD_QUEUE"
fi
queueCmd=" -q $queue "

if [ "$cuda_job" ]; then

    #
    # Configure CUDA hardware version
    #
    if [ -n "$cuda_type" ] && [ "$cuda_classes_available" ]; then
        map_gpu_class "$cuda_type"
    fi
    #
    # Configure CUDA Toolkit version
    #
    if [ "$cuda_uses_modules" ]; then
        cuda_module="$cuda_modules/$cuda_version"
        cuda_module_available=$(module avail "$cuda_module" 2>&1)
        if [ -z "$cuda_module_available" ]; then
            echo "CUDA SDK $cuda_version not found!" >&2
            width=$(tput cols)
            echo "Available modules: $cuda_modules_available" | fold -w "$width" >&2
            usage "$NO_CUDA_VERSION"
        fi
        module add "$cuda_module"
    fi

    #
    # Configure multi-GPU CUDA support
    #
    add_complex "$cuda_gpu_resource" "$cuda_multi_gpu"
fi

if [ -z "$taskfile" ] && [ -z "$1" ]; then
	echo "Either supply a command to run or a parallel task file" >&2
	usage "$NO_EXECUTABLE"
fi

if [ -z "$taskfile" ] && [ ! -x "$1" ]; then
	if command -v "$1" >/dev/null 2>&1; then
		echo "The command you have requested cannot be found or is not executable" >&2
		exit "$NO_EXECUTABLE"
	fi
fi

if [ -n "$taskfile" ]; then
    if [ -n "$max_parallel_tasks" ]; then
        max_parallel_tasks="-tc ${max_parallel_tasks}"
    fi
    # Validate commands in task file
    lno=1
    while read line; do
        tf_cmd=$(echo "$line" | cut -d ' ' -f1)
        if command -v "${tf_cmd}" >/dev/null 2>&1; then
            echo "The command $tf_cmd in the task file $taskfile, line $lno cannot be found or is not executable" >&2
            exit "$NO_EXECUTABLE"
        fi
        lno=$(( "$lno" + 1 ))
    done < "$taskfile"
elif [ -n "$max_parallel_tasks" ]; then
    echo "-x option ignored as not a parallel task job" >&2
    max_parallel_tasks=""
fi

if [ -z "$JobName" ] ; then 
    if [ -n "$taskfile" ] ; then
        JobName=$(basename "$taskfile")
    else
	    JobName=$(basename "$1")
    fi
fi

if [ -n "$tasks" ] && [ -n "$@" ] ; then
    echo "Spurious input after parsing command line:" "$@" >&2
    echo "You appear to have specified both a task file and a command to run" >&2
    usage "$INVALID_SYNTAX"
fi

if [ -n "$peName" ]; then
    # If the PE name is 'openmp' then limit the number of threads to those specified
    if [ "$peName" = "$omp_pe" ]; then
        OMP_NUM_THREADS="$peThreads"
	    export OMP_NUM_THREADS
    fi
fi

case $METHOD in

###########################################################################
# The following is the main call to the cluster, using the "qsub" SGE
# program. If $tasks has not been set then qsub is running a single
# command, otherwise qsub is processing a text file of parallel
# commands.
###########################################################################

    SGE)
       ###########################################################################
       # Test Parallel environment options
       ###########################################################################
	if [ "x$peName" != x ]; then
            # Is this a configured PE?

	    $QCONF -sp "$peName" >/dev/null 2>&1

	    if [ $? -eq 1 ]; then
		    echo "$@" >&2
		    echo "$peName is not a valid PE" >&2
		    exit "$INVALID_SYNTAX"
	    fi

        # Get a list of queues configured for this PE and confirm that the queue
        # we have submitted to has that PE set up.
	    qstat -g c -pe "$peName" >/dev/null 2>&1
	    if [ $? -eq 1 ]; then
		    echo "No parallel environments configured!" >&2
		    exit "$MISS_CONFIGURED"
	    fi

	    qstat -g c -pe "$peName" | sed '1,2d' | awk '{ print $1 }' | grep "^$queue" >/dev/null 2>&1

        if [ $? -eq 1 ]; then
	    	echo "$@"
		    echo "PE $peName is not configured on $queue" >&2
		    exit "$MISS_CONFIGURED"
	    fi

	    # The -w e option will result in the job failing if there are insufficient slots
        # on any of the cluster nodes
	    pe_options="-pe $peName $peThreads -w e"

	fi

	if [ "x$tasks" = "x" ] ; then
	    if [ "$scriptmode" -ne 1 ] ; then
		    sge_command="qsub -cwd -shell n -b y -r y $queueCmd $proc_affinities $sge_priority $complexes $pe_options -M $mailto -N $JobName -m $MailOpts $LogOpts $sge_arch $RAM $sge_hold"
	    else
		    sge_command="qsub $proc_affinities $sge_priority $complexes $pe_options $LogOpts $sge_arch $sge_hold"
	    fi
	    if [ "$verbose" -eq 1 ] ; then 
	    	echo "sge_command: $sge_command" >&2
		    echo "executing: " "$@" >&2
	    fi
	    exec "$sge_command" "$@" | awk '{print $3}'
	else
	    sge_command="qsub -cwd $queueCmd $proc_affinities $sge_priority $complexes $pe_options -M $mailto -N $JobName -m $MailOpts $LogOpts $sge_arch $RAM $sge_hold $sge_tasks"
	    if [ "$verbose" -eq 1 ] ; then 
    		echo "sge_command: $sge_command" >&2
    		echo "control file: $taskfile" >&2
	    fi
	    exec "$sge_command" <<EOF | awk '{print $3}' | awk -F. '{print $1}'
#!/bin/sh

#$ -S /bin/sh

command=\$\(sed -n -e "\${SGE_TASK_ID}p" $taskfile\$\)

exec /bin/sh -c "\$command"
EOF
	fi
	;;

###########################################################################
# Don't change the following - this runs the commands directly if a
# cluster is not being used.
###########################################################################

    NONE)
	if [ "x$tasks" = "x" ] ; then
	    if [ "$verbose" -eq 1 ] ; then 
		    echo "executing: " "$@" >&2
	    fi

	    /bin/sh <<EOF1 > ${LogDir}${JobName}.o$$ 2> ${LogDir}${JobName}.e$$
$@
EOF1
	    ERR=$?
	    if [ "$ERR" -ne 0 ] ; then
		    cat "${LogDir}${JobName}.e$$" >&2
		    exit $ERR
	    fi
	else
	    if [ "$verbose" -eq 1 ] ; then 
		echo "Running commands in: $taskfile" >&2
	    fi

	    n=1
	    while [ "$n" -le "$tasks" ] ; do
		line=$(sed -n -e ''${n}'p' "$taskfile")
		if [ "$verbose" -eq 1 ] ; then 
		    echo executing: "$line" >&2
		fi
		/bin/sh <<EOF2 > ${LogDir}${JobName}.o$$.$n 2> ${LogDir}${JobName}.e$$.$n
$line
EOF2
		n=$(( "$n" + 1 ))
	    done
	fi	
	echo $$
	;;

esac

###########################################################################
# Done.
###########################################################################
