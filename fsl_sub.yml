# Job submission method to use. Supported values are 'SGE' and 'NONE'
method: SGE
# Default units for RAM given
# (P, T, G, M, K)
ram_units: G

# List all environment variables that control thread usage
# will set these to parallel environment threads
thread_control:
  - OMP_THREADS
  - MKL_NUM_THREADS
  - MKL_DOMAIN_NUM_THREADS
  - OPENBLAS_NUM_THREADS
  - GOTO_NUM_THREADS

method_opts:
  None:
    parallel_envs: []
    same_node_pes: []
    large_job_split_pe: []
    mail_support: False
    map_ram: False
    job_priorities: False
    array_holds: False
    array_limit: False
    architecture: False
    job_resources: False
  SLURM:
    # SLURM doesn't use parallel environments - leave these definitions as is
    parallel_envs:
      - shmem
    same_node_pes:
      - shmem
    large_job_split_pe:
      - shmem
    # Replicate user's shell environment to running job
    copy_environment: True
    # Method used to bind to CPUs - set to None to disable
    # Supported options, linear
    affinity_type: linear
    # How to configure this affinity options are:
    #   threads - set to number of threads required
    #   cores - set to number of cores required
    # See --cpu_bind option to sbatch for other options
    affinity_control: threads
    # Enable Emailing end-user about job status
    mail_support: True
    # Supports job priority setting?
    job_priorities: False
    # Lowest priority
    min_priority: 10000
    # Highest (user) priority
    max_priority: 0
    # Array holds
    array_holds: False
    # Array limits
    array_limits: True
    # Whether to split large memory jobs into shared memory slots
    # If your system is configured with MaxMemPerCPU with accounting
    # then this could be set to False as the system should automatically
    # increase the number of CPUs required to satisfy memory requirements
    map_ram: True
    # Whether to divide up RAM requirements for multi-threaded tasks
    thread_ram_divide: True
    # Enable Emailing end-user about job status
    mail_support: True
    # What mail modes are allowed
    mail_modes:
      b:
        - BEGIN
      e:
        - END
      a:
        - FAIL
        - REQUEUE
      f:
        - ALL
      n:
        - NONE
    # When to email user:
    #   b - begin
    #   e - end
    #   a - fail/abort/requeue
    #   f - all events
    #   n - no events
    mail_mode: a
  SGE:
    # List all parallel environments configured on your cluster here
    parallel_envs:
      - shmem
    # List all shared memory (must run on same node) PEs here
    same_node_pes:
      - shmem
    # Which PE should be used to break up large memory jobs
    large_job_split_pe: shmem
    # Replicate user's shell environment to running job
    copy_environment: True
    # Method used to bind to CPUs - set to None to disable
    # Supported options, linear and slots
    affinity_type: linear
    # How to configure this affinity options are:
    #   threads - set to number of threads required
    #   slots - let GE sort it out automatically (not Univa Grid Engine)
    affinity_control: threads
    # Enable Emailing end-user about job status
    mail_support: True
    # What mail modes are allowed
    mail_modes:
      b:
        - b
      e:
        - e
      a:
        - a
      f:
        - a
        - e
        - b
      n:
        - n
    # When to email user:
    #   a - on abort/requeue
    mail_mode: a
    # Whether to split large memory jobs into shared memory PE slots
    map_ram: True
    # Whether to divide up RAM requirements for multi-threaded tasks
    thread_ram_divide: True
    # Queue complexes that specify RAM usage of a job
    ram_resources:
        - m_mem_free
        - h_vmem
    # Supports job priority setting?
    job_priorities: True
    # Lowest priority
    min_priority: -1023
    # Highest (user) priority
    max_priority: 0
    # Supports parallel holds?
    array_holds: True
    # Supports parallel job limits?
    array_limits: True
    # Enable architecture selection?
    architecture: False
    # Supports job resources?
    job_resources: True

# The following defines configuration options for co-processor queues
# Define queues with a copro key set to the name of the appropriate option
# set and ensure that your queue method has a way of interpreting this
coproc_opts:
  cuda:
    # Which scheduler resource requests GPU facilities
    resource: gpu
    # Whether there are multiple coprocessor classes/types
    classes: True
    # Which scheduler resource requests a coprocessor class
    class_resource: gputype
    # This defines the short code for the types and the resource
    # which will be requested and a documentation string for the help
    # text
    class_types:
      G:
        # Queue resource to request (on SLURM this may be a constraint or type)
        resource: TitanX
        # Documentation about this hardware
        doc: TitanX. No-ECC, single-precision workloads
        # Capability level for this hardware, integer value that
        # allows differentiation between hardware models.
        capability: 1
      K:
        resource: k80
        doc: Kepler. ECC, double- or single-precision workloads
        capability: 2
      P:
        resource: p100
        doc: >
          Pascal. ECC, double-, single- and half-precision
          workloads
        capability: 3
      V:
        resource: v100
        doc: >
          Volta. ECC, double-, single-, half-
          and quarter-precision workloads
        capability: 4
    # If a class is not specified, which class should we use?
    default_class: K
    # Should we also allow running on more capable hardware?
    # Requires constraints on SLURM
    include_more_capable: True
    # Should we use Shell modules to load the environment settings for
    # the hardware?
    uses_modules: True
    # What is the name of the parent module for this co-processor?
    module_parent: cuda
    # Should we disable core binding for co-processor tasks?
    no_binding: True
    # Does the SURLM cluster use constraints to specify GPU types?
    slurm_constraints: True
# Queue definitions (Partitions in SLURM)
queues:
  # Queue name
  gpu.q:
    # Maximum job rum time
    time: 18000
    # Maximum memory per job (GB)
    max_size: 250
    # Maximum memory per CPU core (GB)
    slot_size: 64
    # Maximum number of threads per job (e.g. number of CPU cores)
    max_slots: 20
    # Available coprocessors
    copros:
      # Coprocessor name (same as configuration above)
      cuda:
        # Number of devices available per job (e.g. number of devices on a single node)
        max_quantity: 4
        # List of available classes
        classes:
          - K
          - P
          - V
    # Should jobs be split over multiple slots when requires more RAM than available
    # in a single slot
    map_ram: true
    # List of available parallel environments
    parallel_envs:
      - shmem
    # Priority of queue, higher numbers win
    priority: 1
    # Group of queue - use this to group together variations of a queue based on
    # hardware types, the priority is then used to decide which variant to use
    group: 0
  short.qf,short.qe,short.qc:
    time: 1440
    max_size: 160
    slot_size: 4
    max_slots: 16
    map_ram: true
    parallel_envs:
      - shmem
    priority: 3
    group: 1
  short.qe,short.qc:
    time: 1440
    max_size: 240
    slot_size: 16
    max_slots: 16
    map_ram: true
    parallel_envs:
      - shmem
    priority: 2
    group: 1
  short.qc:
    time: 1440
    max_size: 368
    slot_size: 16
    max_slots: 24
    map_ram: true
    parallel_envs:
      - shmem
    priority: 1
    group: 1
  long.qf,long.qe,long.qc:
    time: 10080
    max_size: 160
    slot_size: 4
    max_slots: 16
    map_ram: true
    parallel_envs:
      - shmem
    priority: 3
    group: 2
  long.qe,long.qc:
    time: 10080
    max_size: 240
    slot_size: 16
    max_slots: 16
    map_ram: true
    parallel_envs:
      - shmem
    priority: 2
    group: 2
  long.qc:
    time: 10080
    max_size: 368
    slot_size: 16
    max_slots: 24
    map_ram: true
    parallel_envs:
      - shmem
    priority: 1
    group: 2
